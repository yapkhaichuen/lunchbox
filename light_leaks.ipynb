{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yapkhaichuen/lunchbox/blob/main/light_leaks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI_KS31_e9Ia"
      },
      "source": [
        "# Light leaks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7v8XObsrudn"
      },
      "source": [
        "This project is a photographic post-processing tool designed to add natural-looking, film-inspired light leaks to images while intelligently avoiding faces using advanced face detection. It supports single and batch processing, auto-clears intermediate previews, and runs efficiently with optimized Gaussian blur.\n",
        "\n",
        "#### Key Features:\n",
        "1. Face-Aware Light Leak Placement using:\n",
        "MTCNN for high-quality detection.\n",
        "Fallback to LBP and Haar Profile for side-profile and robustness.\n",
        "2. Fast Gaussian Blur using OpenCV for speed.\n",
        "3. Batch processing with auto directory handling.\n",
        "4. Inline face detection previews (for notebooks) and preview images saved in a cache folder.\n",
        "5. Cleanup utility to remove all generated files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QGRc7Wxd3if"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7tGYFVrmhH-"
      },
      "outputs": [],
      "source": [
        "!pip -q install facenet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUOw6vCYZWO0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from facenet_pytorch import MTCNN\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "\n",
        "# -------- SETUP --------\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "mtcnn = MTCNN(keep_all=True, thresholds=[0.8, 0.85, 0.95], min_face_size=50, device=device)\n",
        "\n",
        "\n",
        "# -------- UTILITY --------\n",
        "def clear_directory(path):\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path)\n",
        "    print(f\"Cleared: {path}\")\n",
        "\n",
        "\n",
        "# -------- FACE DETECTION --------\n",
        "def detect_faces(image, min_confidence=0.9):\n",
        "    # Primary: MTCNN\n",
        "    boxes, probs = mtcnn.detect(image)\n",
        "    if boxes is not None and probs is not None:\n",
        "        faces = [tuple(map(int, box)) for box, p in zip(boxes, probs) if p and p >= min_confidence]\n",
        "        if faces:\n",
        "            return faces\n",
        "\n",
        "    # Fallback: OpenCV LBP (auto-download if not found)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    lbp_path = os.path.join(cv2.data.haarcascades, 'lbpcascade_frontalface_improved.xml')\n",
        "    if not os.path.exists(lbp_path):\n",
        "        print(\"‚¨áÔ∏è Downloading LBP cascade...\")\n",
        "        lbp_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/lbpcascades/lbpcascade_frontalface_improved.xml'\n",
        "        try:\n",
        "            urllib.request.urlretrieve(lbp_url, lbp_path)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not download LBP cascade: {e}\")\n",
        "\n",
        "    if not os.path.exists(lbp_path):\n",
        "        print(\"‚ö†Ô∏è LBP cascade could not be downloaded. Falling back to Haar.\")\n",
        "        lbp_path = os.path.join(cv2.data.haarcascades, 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    detector = cv2.CascadeClassifier(lbp_path)\n",
        "    fallback_faces = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
        "    if len(fallback_faces) > 0:\n",
        "        return [tuple((x, y, x + w, y + h)) for (x, y, w, h) in fallback_faces]\n",
        "\n",
        "    # Fallback: Haar Profile (for side faces)\n",
        "    profile_path = os.path.join(cv2.data.haarcascades, 'haarcascade_profileface.xml')\n",
        "    profile_detector = cv2.CascadeClassifier(profile_path)\n",
        "    profile_faces = profile_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
        "    if len(profile_faces) > 0:\n",
        "        return [tuple((x, y, x + w, y + h)) for (x, y, w, h) in profile_faces]\n",
        "\n",
        "    # Final fallback: return empty list\n",
        "    return []\n",
        "\n",
        "\n",
        "# -------- LIGHT LEAK FUNCTIONS --------\n",
        "def random_color():\n",
        "    palette = [\n",
        "        np.array([1.0, np.random.uniform(0.2, 0.4), 0.0]),\n",
        "        np.array([1.0, 0.0, np.random.uniform(0.2, 0.6)]),\n",
        "        np.array([np.random.uniform(0.8, 1.0), np.random.uniform(0.3, 0.6), 0.0]),\n",
        "        np.array([np.random.uniform(0.7, 1.0), 0.0, np.random.uniform(0.3, 0.6)]),\n",
        "    ]\n",
        "    color_a = palette[np.random.randint(len(palette))]\n",
        "    color_b = palette[np.random.randint(len(palette))]\n",
        "    return color_a, color_b\n",
        "\n",
        "def gaussian_blur_fast(image, sigma):\n",
        "    ksize = int(2 * round(sigma * 3) + 1)\n",
        "    ksize = max(3, ksize | 1)\n",
        "    return cv2.GaussianBlur(image, (ksize, ksize), sigmaX=sigma, sigmaY=sigma)\n",
        "\n",
        "def generate_light_leak_mask(shape, faces=None, num_leaks=3):\n",
        "    h, w = shape[:2]\n",
        "    final_mask = np.zeros((h, w), dtype=np.float32)\n",
        "    y, x = np.ogrid[:h, :w]\n",
        "    center_x, center_y = w / 2, h / 2\n",
        "    distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
        "    prob_map = (distance / distance.max())**2\n",
        "\n",
        "    face_mask = np.ones((h, w), dtype=np.float32)\n",
        "    if faces:\n",
        "        for (x1, y1, x2, y2) in faces:\n",
        "            x1c, y1c = max(x1, 0), max(y1, 0)\n",
        "            x2c, y2c = min(x2, w), min(y2, h)\n",
        "            face_mask[y1c:y2c, x1c:x2c] = 0.0\n",
        "        prob_map *= face_mask\n",
        "\n",
        "    prob_map /= prob_map.sum() + 1e-8\n",
        "    coords = np.argwhere(prob_map > 0)\n",
        "\n",
        "    for _ in range(num_leaks):\n",
        "        for attempt in range(30):\n",
        "            idx = np.random.choice(len(coords))\n",
        "            cy, cx = coords[idx]\n",
        "            shape_type = np.random.choice(['ellipse', 'streak', 'radial'])\n",
        "            temp = np.zeros_like(final_mask)\n",
        "\n",
        "            if shape_type == 'ellipse':\n",
        "                axes = (np.random.randint(w // 10, w // 3), np.random.randint(h // 10, h // 3))\n",
        "                angle = np.random.uniform(0, 360)\n",
        "                cv2.ellipse(temp, (cx, cy), axes, angle, 0, 360, color=1, thickness=-1)\n",
        "            elif shape_type == 'streak':\n",
        "                length = np.random.randint(w // 4, w)\n",
        "                thickness = np.random.randint(20, 80)\n",
        "                angle = np.random.uniform(0, 360)\n",
        "                dx = int(length * np.cos(np.deg2rad(angle)) / 2)\n",
        "                dy = int(length * np.sin(np.deg2rad(angle)) / 2)\n",
        "                pt1 = (np.clip(cx - dx, 0, w-1), np.clip(cy - dy, 0, h-1))\n",
        "                pt2 = (np.clip(cx + dx, 0, w-1), np.clip(cy + dy, 0, h-1))\n",
        "                cv2.line(temp, pt1, pt2, color=1, thickness=thickness)\n",
        "            elif shape_type == 'radial':\n",
        "                radial = np.zeros_like(temp)\n",
        "                cv2.circle(radial, (cx, cy), np.random.randint(h//8, h//2), color=1, thickness=-1)\n",
        "                sigma = np.random.uniform(60, 160)\n",
        "                temp = gaussian_blur_fast(radial, sigma)\n",
        "\n",
        "            if np.all(temp * face_mask == temp):\n",
        "                intensity = np.random.uniform(0.5, 1.2)\n",
        "                final_mask += temp * intensity\n",
        "                break\n",
        "\n",
        "    sigma_final = np.random.uniform(60, 180)\n",
        "    blurred = gaussian_blur_fast(final_mask, sigma_final)\n",
        "    blurred = blurred / blurred.max() if blurred.max() > 0 else blurred\n",
        "    opacity = np.random.uniform(0.4, 0.9)\n",
        "    return np.clip(blurred * opacity, 0, 1)\n",
        "\n",
        "def generate_colored_leak(mask):\n",
        "    mask = mask[..., None]\n",
        "    color_a, color_b = random_color()\n",
        "    t = np.random.rand()\n",
        "    gradient_color = np.clip(color_a + t * (color_b - color_a), 0, 1)\n",
        "    brightness = np.random.uniform(1.0, 1.6)\n",
        "    leak_rgb = mask * gradient_color * brightness\n",
        "    noise = np.random.normal(scale=np.random.uniform(0.01, 0.04), size=mask.shape)\n",
        "    return np.clip(leak_rgb + noise, 0, 1)\n",
        "\n",
        "def blend_screen(base, leak):\n",
        "    return 1 - (1 - base) * (1 - leak)\n",
        "\n",
        "\n",
        "# -------- SINGLE IMAGE PROCESSING --------\n",
        "def apply_light_leak(image_path, output_subdir='applied', cache_dir='cache'):\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    os.makedirs(output_subdir, exist_ok=True)\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"‚ö†Ô∏è Could not load: {image_path}\")\n",
        "        return\n",
        "\n",
        "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_float = rgb_img / 255.0\n",
        "    faces = detect_faces(rgb_img)\n",
        "    print(f\"  ‚û§ Faces detected: {len(faces)}\")\n",
        "\n",
        "    preview_img = rgb_img.copy()\n",
        "    for (x1, y1, x2, y2) in faces:\n",
        "        cv2.rectangle(preview_img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
        "    preview_filename = os.path.join(cache_dir, os.path.basename(image_path))\n",
        "    Image.fromarray(preview_img).save(preview_filename)\n",
        "\n",
        "    # Inline preview in notebooks\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.imshow(preview_img)\n",
        "    plt.title(\"Detected Face Preview\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    combined_leak = np.zeros_like(img_float)\n",
        "    for _ in range(np.random.randint(2, 5)):\n",
        "        mask = generate_light_leak_mask(img.shape, faces=faces, num_leaks=1)\n",
        "        colored_leak = generate_colored_leak(mask)\n",
        "        combined_leak = blend_screen(combined_leak, colored_leak)\n",
        "\n",
        "    result = blend_screen(img_float, combined_leak)\n",
        "    result = np.clip(result * 255, 0, 255).astype(np.uint8)\n",
        "    output_path = os.path.join(output_subdir, os.path.basename(image_path))\n",
        "    Image.fromarray(result).save(output_path)\n",
        "    print(f\"  ‚úÖ Saved: {output_path}\")\n",
        "\n",
        "\n",
        "# -------- BATCH PROCESSING --------\n",
        "def apply_light_leak_batch(source='inputs'):\n",
        "    cache_dir = os.path.join(source, 'cache')\n",
        "    clear_directory(cache_dir)\n",
        "\n",
        "    images = [f for f in os.listdir(source) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    if not images:\n",
        "        print(\"‚ö†Ô∏è No images found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìÅ Processing {len(images)} image(s) in '{source}'...\\n\")\n",
        "\n",
        "    for fname in images:\n",
        "        img_path = os.path.join(source, fname)\n",
        "        output_dir = os.path.join(source, 'applied')\n",
        "        apply_light_leak(img_path, output_subdir=output_dir, cache_dir=cache_dir)\n",
        "\n",
        "\n",
        "# -------- CLEANUP --------\n",
        "def cleanup_all(source='inputs'):\n",
        "    for sub in ['applied', 'cache']:\n",
        "        full = os.path.join(source, sub)\n",
        "        if os.path.exists(full):\n",
        "            shutil.rmtree(full)\n",
        "            print(f\"üßπ Removed: {full}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX6v11kNd7yJ"
      },
      "source": [
        "## Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "236uWLTNnliC"
      },
      "outputs": [],
      "source": [
        "# Run batch from Google Drive!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7Rb0mpelc9Pw"
      },
      "outputs": [],
      "source": [
        "# Batch run on 'input' folder\n",
        "apply_light_leak_batch('input')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGUyFaCIdAbL",
        "outputId": "432b84f9-a5b4-4390-b20b-dcf1dbc3b43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßπ Removed: morestuff/applied\n",
            "üßπ Removed: morestuff/cache\n"
          ]
        }
      ],
      "source": [
        "# Cleans /../applied and /../cache\n",
        "cleanup_all('')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3QGRc7Wxd3if"
      ],
      "provenance": [],
      "mount_file_id": "1OFi5eCMeeDZqunDwCUwhjAaRQOt3ESIW",
      "authorship_tag": "ABX9TyMKRMilFhI4z4ik6XDVTRzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}